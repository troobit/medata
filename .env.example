# =============================================================================
# MEDATA - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in the values for the providers you want to use.
# All variables are optional - only configure the providers you need.
# Settings from .env are merged with user settings from localStorage.
# User settings take precedence over environment variables.
# =============================================================================

# -----------------------------------------------------------------------------
# Default AI Provider (optional)
# Options: foundry, openai, gemini, claude, azure, bedrock, local
# Note: 'foundry' is recommended for Azure users (uses v1 API)
# -----------------------------------------------------------------------------
VITE_AI_PROVIDER=

# -----------------------------------------------------------------------------
# OpenAI Configuration
# https://platform.openai.com/api-keys
# -----------------------------------------------------------------------------
VITE_OPENAI_API_KEY=

# -----------------------------------------------------------------------------
# Google Gemini Configuration
# https://aistudio.google.com/app/apikey
# -----------------------------------------------------------------------------
VITE_GEMINI_API_KEY=

# -----------------------------------------------------------------------------
# Anthropic Claude Configuration
# https://console.anthropic.com/settings/keys
# -----------------------------------------------------------------------------
VITE_CLAUDE_API_KEY=

# -----------------------------------------------------------------------------
# Azure AI Foundry Configuration (RECOMMENDED for Azure users)
# Uses the v1 API - simpler setup, no api-version required
# https://learn.microsoft.com/en-us/azure/ai-foundry/
# -----------------------------------------------------------------------------
VITE_AZURE_FOUNDRY_API_KEY=
VITE_AZURE_FOUNDRY_ENDPOINT=         # e.g., https://your-resource.openai.azure.com
VITE_AZURE_FOUNDRY_MODEL=            # e.g., gpt-4o (optional, defaults to gpt-4o)

# -----------------------------------------------------------------------------
# Azure OpenAI Service (Classic) Configuration
# Use this if you need the classic API with api-version parameter
# https://portal.azure.com/ > Azure OpenAI
# -----------------------------------------------------------------------------
VITE_AZURE_OPENAI_API_KEY=
VITE_AZURE_OPENAI_ENDPOINT=          # e.g., https://your-resource.openai.azure.com
VITE_AZURE_OPENAI_DEPLOYMENT=        # e.g., gpt-4o
VITE_AZURE_OPENAI_API_VERSION=       # e.g., 2024-02-15-preview

# -----------------------------------------------------------------------------
# Amazon Bedrock Configuration
# https://aws.amazon.com/bedrock/
# -----------------------------------------------------------------------------
VITE_AWS_ACCESS_KEY_ID=
VITE_AWS_SECRET_ACCESS_KEY=
VITE_AWS_REGION=                     # e.g., us-east-1
VITE_BEDROCK_MODEL_ID=               # e.g., anthropic.claude-3-sonnet-20240229-v1:0

# -----------------------------------------------------------------------------
# Local Model Configuration (Ollama, LM Studio, etc.)
# -----------------------------------------------------------------------------
VITE_LOCAL_MODEL_ENDPOINT=           # e.g., http://localhost:11434/api (Ollama)
                                     #       http://localhost:1234/v1 (LM Studio)
VITE_LOCAL_MODEL_NAME=               # e.g., llava, bakllava, llava-llama3
VITE_LOCAL_MODEL_TYPE=               # Options: ollama, lmstudio, openai-compatible
